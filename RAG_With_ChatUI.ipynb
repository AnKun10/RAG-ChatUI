{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPH0XJBHFxP/fxCKdekt4Te"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **A, RAG with terminal**"],"metadata":{"id":"113E35SBGZGG"}},{"cell_type":"markdown","source":["# **1, Import ibraries**"],"metadata":{"id":"YuhIH6X91owl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6UHq32oW1kJD"},"outputs":[],"source":["!pip install -q transformers==4.41.2\n","!pip install -q bitsandbytes==0.43.1\n","!pip install -q accelerate==0.31.0\n","!pip install -q langchain==0.2.5\n","!pip install -q langchainhub==0.1.20\n","!pip install -q langchain-chroma==0.1.1\n","!pip install -q langchain-community==0.2.5\n","!pip install -q langchain_huggingface==0.0.3\n","!pip install -q python-dotenv==1.0.1\n","!pip install -q pypdf==4.2.0\n","!pip install -q numpy==1.24.4"]},{"cell_type":"code","source":["import torch\n","\n","from transformers import BitsAndBytesConfig\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","from langchain_huggingface import HuggingFaceEmbeddings\n","from langchain_huggingface.llms import HuggingFacePipeline\n","\n","from langchain.memory import ConversationBufferMemory\n","from langchain_community.chat_message_histories import ChatMessageHistory\n","from langchain_community.document_loaders import PyPDFLoader, TextLoader\n","from langchain.chains import ConversationalRetrievalChain\n","\n","from langchain_chroma import Chroma\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain import hub"],"metadata":{"id":"ZzDiAQJ-41RQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **2, Import the dataset**"],"metadata":{"id":"C2SPpBgb5n6q"}},{"cell_type":"code","source":["!gdown \"1lWuq0COKnU9mCfMvTEq54DBLgAh3yYDx\" -O '/content/'"],"metadata":{"id":"2NaprZuN5wPZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Loader = PyPDFLoader\n","FILE_PATH = \"/content/YOLOv10_Tutorials.pdf\"\n","loader = Loader(FILE_PATH)\n","documents = loader.load()"],"metadata":{"id":"YxTv5Tdl6os3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **3, Create text splitter**"],"metadata":{"id":"2aebOMTG6_lt"}},{"cell_type":"code","source":["text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n","docs = text_splitter.split_documents(documents)\n","print(\"Number of sub-documents: \", len(docs))\n","print(docs[0])"],"metadata":{"id":"ugH8Kw_O6-rP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **4, Create vector database**"],"metadata":{"id":"1KKAawe07rWV"}},{"cell_type":"code","source":["embedding = HuggingFaceEmbeddings()\n","vector_db = Chroma.from_documents(documents=docs ,embedding=embedding)\n","retriever = vector_db.as_retriever()\n","\n","result = retriever.invoke(\"What is YOLO?\")\n","print(\"Number of relevant documents: \", len(result))"],"metadata":{"id":"7NA73_GG7u8p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **5, Create model**"],"metadata":{"id":"S_LsFjFb8TIZ"}},{"cell_type":"code","source":["# Config model\n","nf4_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")"],"metadata":{"id":"nFCbyvr18cTG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create model & tokenizer\n","MODEL_NAME = \"lmsys/vicuna-7b-v1.5\"\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    quantization_config=nf4_config,\n","    low_cpu_mem_usage=True\n",")\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"],"metadata":{"id":"dkuIBh-h9L3k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create model pipeline\n","model_pipeline = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    device_map=\"auto\",\n","    max_new_tokens=512,\n","    pad_token_id=tokenizer.eos_token_id\n",")\n","\n","llm = HuggingFacePipeline(pipeline=model_pipeline)"],"metadata":{"id":"aWtp2vJX9roy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **6, Test model**"],"metadata":{"id":"N2pqiXUm_FAC"}},{"cell_type":"code","source":["prompt = hub.pull(\"rlm/rag-prompt\")\n","\n","def format_docs(docs):\n","  return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","rag_chain = (\n","    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n","    | prompt\n","    | llm\n","    | StrOutputParser()\n",")\n","\n","USER_QUESTION = \"YOLOv10 là gì?\"\n","output = rag_chain.invoke(USER_QUESTION)\n","answer = output.split('Answer:')[1].strip()\n","print(answer)"],"metadata":{"id":"gHVbF6y-_MQq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **B, RAG with Chainlit**"],"metadata":{"id":"AhxVXYaPG5cz"}},{"cell_type":"markdown","source":["# **1, Import libraries**"],"metadata":{"id":"eD11frHDG9zT"}},{"cell_type":"code","source":["!pip install -q transformers==4.41.2\n","!pip install -q bitsandbytes==0.43.1\n","!pip install -q accelerate==0.31.0\n","!pip install -q langchain==0.2.5\n","!pip install -q langchainhub==0.1.20\n","!pip install -q langchain-chroma==0.1.1\n","!pip install -q langchain-community==0.2.5\n","!pip install -q langchain-openai==0.1.9\n","!pip install -q langchain_huggingface==0.0.3\n","!pip install -q chainlit==1.1.304\n","!pip install -q python-dotenv==1.0.1\n","!pip install -q pypdf==4.2.0\n","!npm install -g localtunnel\n","!pip install -q numpy==1.24.4"],"metadata":{"id":"A5Qw32P2HEG3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import chainlit as cl\n","import torch\n","\n","from chainlit.types import AskFileResponse\n","\n","from transformers import BitsAndBytesConfig\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","from langchain_huggingface.llms import HuggingFacePipeline\n","\n","from langchain.memory import ConversationBufferMemory\n","from langchain_community.chat_message_histories import ChatMessageHistory\n","from langchain.chains import ConversationalRetrievalChain\n","\n","from langchain_huggingface import HuggingFaceEmbeddings\n","from langchain_chroma import Chroma\n","from langchain_community.document_loaders import PyPDFLoader, TextLoader\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain import hub"],"metadata":{"id":"jhG5BKsMHko6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **2, Create text splitter & vector database**"],"metadata":{"id":"eSeddvYNIL7b"}},{"cell_type":"code","source":["text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n","\n","embedding = HuggingFaceEmbeddings()"],"metadata":{"id":"tqTJAcO5IKKk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_file(file: AskFileResponse):\n","  if file.type == \"text/plain\":\n","    Loader = TextLoader\n","  elif file.type == \"application/pdf\":\n","    Loader = PyPDFLoader\n","\n","  loader = Loader(file.content)\n","  documents = loader.load()\n","  docs = text_splitter.split_documents(documents)\n","  for i, doc in enumerate(docs):\n","    doc.metadata[\"source\"] = f\"source_{i}\"\n","  return docs"],"metadata":{"id":"1Q1CLoy9IqaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_vector_db(file: AskFileResponse):\n","  docs = process_file(file)\n","  cl.user_session.set(\"docs\", docs)\n","  vector_db = Chroma.from_documents(documents=docs, embedding=embedding)\n","  return vector_db"],"metadata":{"id":"0QZc_WLyJf-W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **3, Create model**"],"metadata":{"id":"TSZMQk2gKHLW"}},{"cell_type":"code","source":["def get_huggingface_llm(model_name: str = \"lmsys/vicuna-7b-v1.5\", max_new_token: int = 512) :\n","  nf4_config = BitsAndBytesConfig(\n","      load_in_4bit=True,\n","      bnb_4bit_quant_type=\"nf4\",\n","      bnb_4bit_use_double_quant=True ,\n","      bnb_4bit_compute_dtype=torch.bfloat16\n","  )\n","  model = AutoModelForCausalLM.from_pretrained(\n","      model_name,\n","      quantization_config = nf4_config,\n","      low_cpu_mem_usage = True\n","  )\n","  tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","  model_pipeline = pipeline(\n","      \"text-generation\",\n","       model=model,\n","       tokenizer = tokenizer,\n","       max_new_tokens = max_new_token,\n","       pad_token_id = tokenizer.eos_token_id,\n","       device_map=\"auto\"\n","  )\n","\n","  llm = HuggingFacePipeline(\n","      pipeline=model_pipeline\n","  )\n","  return llm\n","\n","LLM = get_huggingface_llm()"],"metadata":{"id":"pIubpnGwJ7t4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **4, Create message**"],"metadata":{"id":"a3M-_GNDMZEz"}},{"cell_type":"code","source":["# Create welcome message\n","welcome_message = \"\"\"Welcome to the PDF QA! To get started:\n","1. Upload a PDF or text file\n","2. Ask a question about the file\n","\"\"\""],"metadata":{"id":"A7yDTATKMgaG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create on_chat_start\n","@cl.on_chat_start\n","async def on_chat_start():\n","  files = None\n","  while files is None:\n","    files = await cl.AskFileMessage(\n","        content=welcome_message,\n","        accept =[\"text/plain\", \"application/pdf\"],\n","        max_size_mb=20,\n","        timeout =180\n","    ).send()\n","  file = files[0]\n","\n","  msg = cl.Message(content=f\"Processing '{file.name}'...\",\n","                   disable_feedback=True)\n","  await msg.send()\n","\n","  vector_db = await cl.make_async(get_vector_db)(file)\n","\n","  message_history = ChatMessageHistory()\n","  memory = ConversationBufferMemory(\n","      memory_key =\"chat_history\",\n","      output_key =\"answer\",\n","      chat_memory = message_history,\n","      return_messages =True\n","  )\n","  retriever = vector_db.as_retriever(search_type =\"mmr\",\n","                                     search_kwargs ={'k': 3})\n","\n","  chain = ConversationalRetrievalChain.from_llm(llm=LLM,\n","                                                chain_type=\"stuff\",\n","                                                retriever=retriever,\n","                                                memory=memory,\n","                                                return_source_documents=True)\n","\n","  msg.content = f\"'{file.name}' processed. You can now ask questions!\"\n","  await msg.update()\n","\n","  cl.user_session.set(\"chain\", chain)"],"metadata":{"id":"HkHuM8K7MuCe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create on_message\n","@cl.on_message\n","async def on_message(message:cl.Message):\n","  chain = cl.user_session.get(\"chain\")\n","  cb = cl.AsyncLangchainCallbackHandler()\n","  res = await chain.ainvoke(message.content, callbacks=[cb])\n","  answer = res[\"answer\"]\n","  source_documents = res[\"source_documents\"]\n","  text_elements = []\n","\n","  if source_documents:\n","    for source_idx, source_doc in enumerate(source_documents):\n","        source_name = f\"source_{source_idx}\"\n","        text_elements.append(\n","            cl.Text(content = source_doc.page_content,\n","                    name = source_name)\n","        )\n","    source_names = [text_el.name for text_el in text_elements ]\n","\n","    if source_names:\n","      answer += f\"\\nSources : {', '.join(source_names)}\"\n","    else:\n","      answer += \"\\nNo sources found\"\n","\n","  await cl.Message(content = answer, elements = text_elements).send()"],"metadata":{"id":"WmQ85HNyQVDt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **5, Run chainlit**"],"metadata":{"id":"SQ3pyxGoTKZf"}},{"cell_type":"code","source":["!chainlit run app.py --host 0.0.0.0 --port 8000 &>/content/logs.txt &\n","import urllib\n","print(\"Password / Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n","!lt --port 8000 --subdomain aivn-simple-rag"],"metadata":{"id":"snc3J7XtTqet"},"execution_count":null,"outputs":[]}]}